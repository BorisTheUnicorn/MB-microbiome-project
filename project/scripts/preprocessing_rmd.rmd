---
title: "Neisseria Meningitidis Microbiome Study - Data Preprocessing"
author: "Orr"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    code_folding: show
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 10,
  fig.height = 6
)
```

# Introduction

This document details the data preprocessing steps for the Neisseria meningitidis (NM) microbiome study. The analysis examines oropharyngeal samples collected at three time points from military recruits in Israel during 2019-2020. We aim to identify microbiome signatures associated with:

1. Susceptibility to NM acquisition
2. Resilience/clearance of NM carriage
3. Temporal patterns and contextual factors affecting these dynamics

## Project Overview

This study builds on previous research that established NM carriage patterns and risk factors in this cohort. Key findings from the original study:

- Overall NM carriage rate: 20.1%
- Encapsulated strains carriage rate: 6.7%
- Identified risk factors for carriage: active smoking, boarding school attendance before recruitment
- Seasonal variations in carriage prevalence

Our microbiome analysis will provide further insights into the microbial ecology associated with NM carriage dynamics.

## Preprocessing Workflow

This document covers:

1. Loading required packages and source functions
2. Importing raw QIIME2 data
3. Batch effect assessment and correction
4. Classification of subjects based on NM carriage dynamics
5. Export of processed data for subsequent analyses

# Setup

## Load Required Packages

```{r load-packages}
# Core packages
library(vegan)
library(ggplot2)
library(patchwork)
library(microbiome)
library(phyloseq)
library(qiime2R)
library(microeco)
library(dplyr)
library(tidyverse)
library(magrittr)
library(sva)
library(GUniFrac)
library(DT)
```

## Source Function Files

```{r source-functions}
# Source function files from the R directory


source(file.path("..", "R", "preprocessing_functions.R"))
source(file.path("..", "R", "visualization_functions.R"))
# source(file.path("..", "R", "differential_abundance.R"))

# Check if any functions were successfully loaded
if(exists("import_qiime2_data") && exists("correct_batch_effect") && exists("classify_carriage_status")) {
  cat("Functions successfully loaded.\n")
} else {
  cat("Warning: Some functions may not have loaded correctly. Please check file paths.\n")
}
```

# Data Import

## Import QIIME2 Data Files

We'll use the custom function `import_qiime2_data()` to load our raw QIIME2 data.

```{r import-data}
# Define paths to input files
metadata_path <- file.path("data", "raw", "00.metadata.combined.2020_2021.tsv") 
feature_table_path <- file.path("data", "raw", "table-dada2.qza")
taxonomy_path <- file.path("data", "raw", "taxonomy-dada2.qza")
tree_path <- file.path("data", "raw", "rooted-tree-dada2.qza")

# Import data and create the microtable dataset
dataset <- import_qiime2_data(
  metadata_path = metadata_path,
  feature_table_path = feature_table_path,
  taxonomy_path = taxonomy_path,
  tree_path = tree_path
)

# Basic dataset overview
cat("Dataset summary:\n")
cat("Number of samples:", nrow(dataset$sample_table), "\n")
cat("Number of features:", nrow(dataset$otu_table), "\n")
cat("Taxonomic levels:", paste(colnames(dataset$tax_table), collapse = ", "), "\n")
```

## Explore Basic Dataset Properties

Let's explore the metadata and sample distribution to better understand our dataset.

```{r explore-metadata}
# Display metadata structure
str(dataset$sample_table)

# Look at time point distribution
cat("Sample distribution by time point:\n")
table(dataset$sample_table$time)

# Look at case-control distribution
cat("Sample distribution by carriage status:\n")
table(dataset$sample_table$case_control)

# Look at batch/year distribution
cat("Sample distribution by batch:\n")
table(dataset$sample_table$batch)
cat("Sample distribution by year:\n")
table(dataset$sample_table$year)

# Examine relationships between these variables
cat("Cross-tabulation of time by case_control:\n")
table(dataset$sample_table$time, dataset$sample_table$case_control)
cat("Cross-tabulation of batch by year:\n")
table(dataset$sample_table$batch, dataset$sample_table$year)
```

## Import Additional Demographics Data

We'll import additional demographic data to incorporate into our analysis.

```{r import-demographics}
# Import demographic data
demographic_data <- readxl::read_excel("data/raw/demographic data _Jan2022_final.YM.20241230.xlsx")

# Clean and prepare demographic data
demographic_data <- demographic_data %>%
  mutate(
    pid = as.character(pid),  # Ensure pid is character for joining
    boardingschool = factor(boardingschool),
    selfsmoking = factor(selfsmoking),
    secondsmoker = factor(secondsmoker),
    AB_month = factor(AB_month),  # Antibiotic use in previous month
    AB_year = factor(AB_year)     # Antibiotic use in previous year
  )

# Add demographic data to sample table (only key variables)
dataset$sample_table <- dataset$sample_table %>%
  left_join(demographic_data %>% 
              select(pid, boardingschool, selfsmoking, secondsmoker, 
                     AB_month, AB_year, yearofbirth, family_members), 
            by = "pid")

# Ensure time is treated as a factor for modeling
dataset$sample_table$time <- factor(dataset$sample_table$time)

# Check for missing data in key variables
cat("Missing data in key demographic variables:\n")
colSums(is.na(dataset$sample_table[, c("boardingschool", "selfsmoking", "secondsmoker", 
                                       "AB_month", "AB_year")]))
```

# Batch Effect Assessment and Correction

## Assess Batch Effects

Before applying batch correction, we should assess the presence and extent of batch effects.

```{r assess-batch-effect}
# Calculate beta diversity for visualization
dataset$cal_betadiv(unifrac = TRUE)

# Create ordination plots to visualize batch effects
batch_ordination <- create_beta_ordination(
  dataset = dataset, 
  factor_name = "batch",
  title = "Batch Effect by Sequencing Batch"
)

year_ordination <- create_beta_ordination(
  dataset = dataset, 
  factor_name = "year",
  title = "Batch Effect by Year"
)

# Display the plots
batch_ordination$plot
year_ordination$plot

# Create ordination by important biological factors for comparison
time_ordination <- create_beta_ordination(
  dataset = dataset, 
  factor_name = "time",
  title = "Samples by Time Point"
)

carriage_ordination <- create_beta_ordination(
  dataset = dataset, 
  factor_name = "case_control",
  title = "Samples by NM Carriage Status"
)

# Display the plots
time_ordination$plot
carriage_ordination$plot
```

## Apply Batch Correction

Based on our observation of batch effects, we'll apply ComBat batch correction.

```{r batch-correction}
# Apply batch correction using the custom function
# Using year as the batch variable, as it's more clearly separated in the PCA
dataset_corrected <- correct_batch_effect(
  dataset = dataset, 
  batch_var = "year",
  method = "simple_log",  # Using log transformation (not CLR) for ComBat
  round_counts = FALSE     # Keep as continuous values for CLR later
)

# Rename objects for clarity
dataset_original <- dataset
dataset <- dataset_corrected

# Calculate beta diversity on corrected data
dataset$cal_betadiv(unifrac = TRUE)
```

## Validate Batch Correction

Let's assess whether the batch correction was effective.

```{r validate-correction}
# Create comparison plots
comparison_plots <- compare_correction_plots(
  dataset_original = dataset_original,
  dataset_corrected = dataset,
  factor_names = c("year", "batch", "time", "case_control"),
  plot_titles = c(
    "Batch Effect by Year", 
    "Batch Effect by Sequencing Batch", 
    "Samples by Time Point", 
    "Samples by NM Carriage Status"
  )
)

# Display the comparison plots
comparison_plots$year
comparison_plots$batch
comparison_plots$time
comparison_plots$case_control

# Clean up unused objects
rm(dataset_original)
rm(batch_ordination, year_ordination, time_ordination, carriage_ordination)
rm(comparison_plots)
```

# Carriage Status Classification

We'll classify subjects based on their NM carriage patterns across time points.

```{r classify-carriage}
# Classify subjects based on carriage patterns
carriage_patterns <- classify_carriage_status(dataset)

# Examine the distribution of carriage statuses
table(carriage_patterns$carriage_status)

# Look at the simplified carriage groups
table(carriage_patterns$carriage_group)

# Add carriage classification to the dataset
dataset <- update_dataset_with_carriage_status(dataset, carriage_patterns)

# Create expanded susceptibility groups
expanded_patterns <- create_susceptibility_groups(carriage_patterns)
dataset <- update_dataset_with_carriage_status(
  dataset, 
  carriage_patterns, 
  expanded_patterns
)

# Check sample counts in each group by time point
cat("Sample counts by carriage group and time point:\n")
table(dataset$sample_table$carriage_group, dataset$sample_table$time)

cat("Sample counts by susceptibility group and time point:\n")
table(dataset$sample_table$susceptibility_group, dataset$sample_table$time)

# Baseline-only counts for the main analysis groups
cat("Baseline-only (time 0) sample counts by carriage group:\n")
table(subset(dataset$sample_table, time == "0")$carriage_group)

cat("Baseline-only (time 0) sample counts by susceptibility group:\n")
table(subset(dataset$sample_table, time == "0")$susceptibility_group)
```

# Data Preparation for Analysis

## Convert to Phyloseq Format

For compatibility with ANCOM-BC2 and other tools, we'll convert our data to the phyloseq format.

```{r convert-to-phyloseq}
# Convert to phyloseq format
ps <- convert_to_phyloseq(dataset)

# Create baseline-only subset for certain analyses
ps_baseline <- subset_samples(ps, time == "0")

# Create susceptibility analysis subset (baseline samples)
ps_suscept <- subset_samples(ps_baseline, 
                           susceptibility_group %in% c("Ever_acquired_NM", "Never_acquired_NM"))

# Create resilience analysis subset (baseline samples)
ps_resilience <- subset_samples(ps_baseline, 
                              carriage_group %in% c("Persistent_carrier", "Clearance_carrier"))

# Check final sample sizes
cat("Full dataset sample count:", nsamples(ps), "\n")
cat("Baseline-only sample count:", nsamples(ps_baseline), "\n")
cat("Susceptibility analysis sample count:", nsamples(ps_suscept), "\n")
cat("Resilience analysis sample count:", nsamples(ps_resilience), "\n")
```

## Export Processed Data

Finally, we'll save the processed datasets for subsequent analyses.

```{r export-data}
# Save the processed datasets
saveRDS(dataset, file = "data/processed/dataset_processed.rds")
saveRDS(ps, file = "data/processed/phyloseq_full.rds")
saveRDS(ps_baseline, file = "data/processed/phyloseq_baseline.rds")
saveRDS(ps_suscept, file = "data/processed/phyloseq_susceptibility.rds")
saveRDS(ps_resilience, file = "data/processed/phyloseq_resilience.rds")
saveRDS(carriage_patterns, file = "data/processed/carriage_patterns.rds")

# Save key metadata for reference
write.csv(dataset$sample_table, file = "data/processed/sample_metadata.csv", row.names = FALSE)
```

# Summary

This preprocessing workflow has accomplished several key tasks:

1. Imported and organized raw QIIME2 data
2. Assessed and corrected batch effects
3. Classified subjects based on NM carriage dynamics
4. Created analysis-specific data subsets
5. Exported processed data for subsequent analyses

The next steps in our analysis will include:

1. Analyzing microbiome signatures associated with NM susceptibility
2. Identifying taxa associated with NM clearance (resilience)
3. Examining temporal patterns and contextual factors

These analyses will be carried out in separate RMarkdown files:
- `02_susceptibility_analysis.Rmd`
- `03_resilience_analysis.Rmd`

```{r session-info}
# Record session information for reproducibility
sessionInfo()
```
